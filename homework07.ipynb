{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "U1lUFaCWW_9l",
    "outputId": "8a2c0cf6-c064-47ec-8d63-18d9279b8022",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# disable compiler warnings\n",
    "import os\n",
    "\n",
    "# imports \n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from typing import List\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'  # FATAL\n",
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "uk6WUyODW_9n"
   },
   "outputs": [],
   "source": [
    "(train_ds, val_ds), ds_info = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)\n",
    "\n",
    "#tfds.show_examples(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class CustomLSTM(tf.keras.layers.AbstractRNNCell):\n",
    "  def __init__(self, units, **kwargs):\n",
    "      self.units = units\n",
    "      super(CustomLSTM, self).__init__(**kwargs)\n",
    "\n",
    "      initializer = tf.keras.initializers.Orthogonal()\n",
    "\n",
    "      self.layer_information_eraser = tf.keras.layers.Dense(self.units, activation='sigmoid', kernel_initializer=initializer)\n",
    "      self.layer_new_information_filter = tf.keras.layers.Dense(self.units, activation='sigmoid', kernel_initializer=initializer)\n",
    "      self.layer_new_information = tf.keras.layers.Dense(self.units, activation='tanh', kernel_initializer=initializer)\n",
    "      self.layer_information_transfer_filter = tf.keras.layers.Dense(self.units, activation='sigmoid', kernel_initializer=initializer)\n",
    "\n",
    "  @property\n",
    "  def state_size(self):\n",
    "    return (self.units, self.units)\n",
    "    #return [tf.TensorShape([self.units]), tf.TensorShape([self.units])]\n",
    "\n",
    "  @property\n",
    "  def output_size(self):\n",
    "    return self.units\n",
    "\n",
    "  #def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "    #return [tf.zeros([self.units], tf.float32), tf.zeros([self.units], tf.float32)]\n",
    "\n",
    "  def call(self, inputs, states):\n",
    "    hidden_state, cell_state = states\n",
    "\n",
    "    hidden_input = tf.concat([inputs, hidden_state], 1)\n",
    "\n",
    "    cell_state = tf.math.multiply(cell_state, self.layer_information_eraser(hidden_input))\n",
    "    cell_state = tf.math.add(cell_state, tf.math.multiply(self.layer_new_information(hidden_input), self.layer_new_information_filter(hidden_input)))\n",
    "\n",
    "    hidden_state = tf.math.multiply(tf.math.tanh(cell_state), self.layer_information_transfer_filter(hidden_input))\n",
    "\n",
    "    return hidden_state, [hidden_state, cell_state]"
   ],
   "metadata": {
    "id": "DEFe60MFOII0"
   },
   "execution_count": 104,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "jVBPWYKzW_9n"
   },
   "outputs": [],
   "source": [
    "class BasicConv(tf.keras.Model):\n",
    "    def __init__(self, seq_size, optimizer=tf.keras.optimizers.Adam()):\n",
    "        super(BasicConv, self).__init__()\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        #self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "        #self.metrics_list = [[tf.keras.metrics.CategoricalAccuracy(name=\"test_accuracy\"),\n",
    "        #                     tf.keras.metrics.Mean(name=\"test_loss\"),\n",
    "        #                     tf.keras.metrics.Mean(name=\"test_frob_norm\")],\n",
    "        #                     [tf.keras.metrics.CategoricalAccuracy(name=\"train_accuracy\"),\n",
    "        #                     tf.keras.metrics.Mean(name=\"train_loss\"),\n",
    "        #                     tf.keras.metrics.Mean(name=\"train_frob_norm\")]]\n",
    "\n",
    "        #self.metrics_list = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        #                     tf.keras.metrics.Mean(name=\"loss\"),\n",
    "        #                     tf.keras.metrics.Mean(name=\"frob_norm\")]\n",
    "\n",
    "        output_size = (int) (9*seq_size+1)\n",
    "  \n",
    "        self.pooling = tf.keras.layers.MaxPooling2D()\n",
    "        self.my_layers = [\n",
    "                        tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "                        tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "                        tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D()),\n",
    "                        tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(14, 14, 1)),\n",
    "                        tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(14, 14, 1)),\n",
    "                        tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAvgPool2D()),\n",
    "                        #tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(10, activation='softmax')),\n",
    "                        #tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='relu')),\n",
    "                        #tf.keras.layers.RNN(CustomLSTM(64), unroll=True, return_sequences=True),\n",
    "                        tf.keras.layers.LSTM(10, unroll=True, return_sequences=True),\n",
    "                        #tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "                        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(output_size, activation='softmax'))\n",
    "                        ]\n",
    "\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, x, training=False):\n",
    "        x = self.my_layers[0](x)\n",
    "        x = self.my_layers[1](x)\n",
    "        x = self.my_layers[2](x)\n",
    "        x = self.my_layers[3](x)\n",
    "        x = self.my_layers[4](x)\n",
    "        x = self.my_layers[5](x)\n",
    "        x = self.my_layers[6](x)\n",
    "        x = self.my_layers[7](x)\n",
    "        #x = self.my_layers[8](x)\n",
    "        #x = tf.round(x)\n",
    "        \n",
    "        #for layer in self.my_layers:\n",
    "        #    tf.print(x)\n",
    "        #    x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @tf.function\n",
    "    def compute_frobenius(self):\n",
    "        frobenius_norm = tf.zeros((1,))\n",
    "        for var in self.trainable_variables:\n",
    "            frobenius_norm += tf.norm(var, ord=\"euclidean\")\n",
    "        return frobenius_norm\n",
    "\n",
    "    # 3. metrics property\n",
    "    #\"\"\"@property\"\"\"\n",
    "    #def metrics(self):\n",
    "    #    return self.metrics_list\n",
    "\n",
    "    # 4. reset all metrics objects\n",
    "    #def reset_metrics(self):\n",
    "    #    for metric in self.metrics:\n",
    "    #      #for metric in metric_list:\n",
    "    #      metric.reset_states()\n",
    "\n",
    "    \"\"\"\n",
    "    # train_step method\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        img, label = data\n",
    "        \n",
    "        # compute output and loss, train the variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self(img, training=True)\n",
    "            loss = self.loss_function(label, output)\n",
    "            \n",
    "        # update trainable variables\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        # update metrics\n",
    "        self.metrics_list[1][0].update_state(tf.argmax(output, axis=1), tf.argmax(label, axis=1))\n",
    "        self.metrics_list[1][1].update_state(loss)\n",
    "        self.metrics_list[1][2].update_state(self.compute_frobenius())\n",
    "        \n",
    "        # return a dict with metric information\n",
    "        return {m.name : m.result() for m in self.metrics_list[1]}\n",
    "\n",
    "\n",
    "\n",
    "    # test_step method\n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        img, label = data\n",
    "\n",
    "        # compute output and loss, without training\n",
    "        output = self(img, training=False)\n",
    "        loss = self.loss_function(label, output)\n",
    "\n",
    "        # update metrics\n",
    "        self.metrics_list[0][0].update_state(tf.argmax(output, axis=1), tf.argmax(label, axis=1))\n",
    "        self.metrics_list[0][1].update_state(loss)\n",
    "        self.metrics_list[0][2].update_state(self.compute_frobenius())\n",
    "\n",
    "        # return a dict with metric information \n",
    "        return {m.name : m.result() for m in self.metrics_list[0]}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "8svy39RCW_9o"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_summary_writers(config_name):\n",
    "    \n",
    "    # Define where to save the logs\n",
    "    # along with this, you may want to save a config file with the same name so you know what the hyperparameters were used\n",
    "    # alternatively make a copy of the code that is used for later reference\n",
    "    \n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    train_log_path = f\"logs/{config_name}/{current_time}/train\"\n",
    "    val_log_path = f\"logs/{config_name}/{current_time}/val\"\n",
    "\n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "    # log writer for validation metrics\n",
    "    val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
    "    \n",
    "    return train_summary_writer, val_summary_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "0R4loQRQW_9p"
   },
   "outputs": [],
   "source": [
    "# gets in a dataset and returns target values\n",
    "def prepare_data(dataset, seq_size, batch_size):\n",
    "\n",
    "    # convert data from uint8 to float32\n",
    "    dataset = dataset.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    # convert image values from range [0, 255] to [-1, 1]\n",
    "    dataset = dataset.map(lambda img, target: ((img/128.)-1., target))\n",
    "\n",
    "    # Create random tuples of 4 images [[img, ...], [target, ...]]\n",
    "    dataset = dataset.batch(seq_size, drop_remainder=True)\n",
    "\n",
    "    #for a, b in dataset:\n",
    "      #print(list(b.as_numpy_iterator()))\n",
    "\n",
    "    for imgs, targets in dataset.take(1):\n",
    "      print(targets)\n",
    "      for target in targets:\n",
    "        print(target)\n",
    "\n",
    "    # Generate cumulative sum targets\n",
    "    def generate_sums(elems):\n",
    "      signs = tf.constant([1 if i % 2 == 0 else -1 for i in range(len(elems))], dtype=tf.int64)\n",
    "      return tf.cumsum(tf.math.multiply(elems, signs))\n",
    "\n",
    "    dataset = dataset.map(lambda imgs, targets: (imgs, generate_sums(targets)))\n",
    "\n",
    "    # Convert targets to one hot vectors\n",
    "    one_hot_depth = (int) (9*seq_size+1)\n",
    "    dataset = dataset.map(lambda imgs, targets: (imgs, tf.one_hot(targets + (int) (one_hot_depth / 2 + 1), depth=one_hot_depth)))\n",
    "\n",
    "    for imgs, targets in dataset.take(1):\n",
    "      print(targets)\n",
    "      for target in targets:\n",
    "        print(target)\n",
    "    \n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(4096)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "GbGZjolXZZGH"
   },
   "outputs": [],
   "source": [
    "# trains the model by iterating through the dataset and applying training_step method epochs time\n",
    "def training_loop(model, train_ds, test_ds, epochs, train_summary_writer, memory):\n",
    "    metrics = []\n",
    "\n",
    "    # iterate over epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        # train steps on all batches in the training data\n",
    "        for (img, label) in train_ds:\n",
    "            metrics = model.train_step((img, label))\n",
    "            \n",
    "            # keep data in summary with metrics\n",
    "            with train_summary_writer.as_default():\n",
    "                for metric in model.metrics_list[1]:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "\n",
    "        for (key, value) in metrics.items():\n",
    "            memory[key].append(value.numpy())\n",
    "\n",
    "        memory = test_loop(model=model,\n",
    "                           test_ds=test_ds,\n",
    "                           val_summary_writer=val_summary_writer,\n",
    "                           memory=memory)\n",
    "        \n",
    "        # print current metric values and reset the metrics\n",
    "        tf.print([f\"{key} : {value.numpy()}\" for (key, value ) in metrics.items()])\n",
    "        model.reset_metrics(1)\n",
    "\n",
    "    return memory\n",
    "\n",
    "\n",
    "# tests overall performance of model\n",
    "def test_loop(model, test_ds, val_summary_writer, memory):\n",
    "    metrics = []\n",
    "    # test steps on every item in test dataset\n",
    "    for (img, label) in tqdm(test_ds):\n",
    "        metrics = model.test_step((img, label))\n",
    "        \n",
    "        # keep data with metrics\n",
    "        with val_summary_writer.as_default():\n",
    "            for metric in model.metrics_list[0]:\n",
    "                tf.summary.scalar(f\"{metric.name}\", metric.result(), step=1)\n",
    "\n",
    "    for (key, value) in metrics.items():\n",
    "        memory[key].append(value.numpy())\n",
    "\n",
    "    print([f\"{key} : {value.numpy()}\" for (key, value ) in metrics.items()])\n",
    "\n",
    "    model.reset_metrics(0)\n",
    "\n",
    "    return memory\n",
    "\n",
    "# visualize accuracy, loss and frobenius norm\n",
    "def visualization(accuracies, losses, frobenius, name):\n",
    "    plt.figure()\n",
    "    line1, = plt.plot(accuracies, \"b\")\n",
    "    line2, = plt.plot(losses, \"r\")\n",
    "\n",
    "    frob_new = frobenius/np.max(frobenius) * np.max(losses)\n",
    "    line3, = plt.plot(frob_new, \"y\" )\n",
    "\n",
    "    plt.xlabel(\"Training steps\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend((line1, line2, line3),(\"Accuracy\", \"Loss\", \"Frobenius Norm\"))\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "dDCxrRjh_WI8"
   },
   "outputs": [],
   "source": [
    "# overall hyperparameters to compare with and without overfitting precautions methods\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "seq_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvQPXaqlBYxF"
   },
   "source": [
    "## no augmentation, normal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "gziNcUqxD-M3",
    "outputId": "eca65d5e-dcad-45ad-8d21-cf9dba07568e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([4 1 0 7], shape=(4,), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(4, 37), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(37,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(37,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(37,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(37,), dtype=float32)\n",
      "tf.Tensor([2 0 4 8], shape=(4,), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(4, 37), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(37,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(37,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(37,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(37,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_summary_writer, val_summary_writer = create_summary_writers(config_name=\"UNTOUCHED\")\n",
    "\n",
    "model = BasicConv(seq_size)\n",
    "\n",
    "\n",
    "#for img, label in train_ds.take(1):\n",
    "#    print(img.shape)\n",
    "#    print(label.shape)\n",
    "\n",
    "train_dataset = prepare_data(train_ds, seq_size, batch_size)\n",
    "#train_dataset = train_ds.apply(lambda dataset: prepare_data(dataset, seq_size, batch_size))\n",
    "val_dataset = prepare_data(val_ds, seq_size, batch_size)\n",
    "#val_dataset = val_ds.apply(lambda dataset: prepare_data(dataset, seq_size, batch_size))\n",
    "\n",
    "#for img, label in train_dataset.take(1):\n",
    "#    print(img.shape)\n",
    "#    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "8G0PkfIFZZGM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "32cbf924-f189-4694-e913-3ec5a50686fd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 12s 19ms/step - loss: 3.1476 - accuracy: 0.0777 - val_loss: 3.0456 - val_accuracy: 0.0871\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 3.0450 - accuracy: 0.0790 - val_loss: 3.0333 - val_accuracy: 0.0818\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 3.0378 - accuracy: 0.0793 - val_loss: 3.0280 - val_accuracy: 0.0809\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 3.0336 - accuracy: 0.0799 - val_loss: 3.0243 - val_accuracy: 0.0832\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 3.0303 - accuracy: 0.0795 - val_loss: 3.0218 - val_accuracy: 0.0832\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 3.0274 - accuracy: 0.0794 - val_loss: 3.0183 - val_accuracy: 0.0809\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 3.0229 - accuracy: 0.0788 - val_loss: 2.9845 - val_accuracy: 0.0733\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 2.9157 - accuracy: 0.0814 - val_loss: 2.8773 - val_accuracy: 0.0855\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 2.7977 - accuracy: 0.1125 - val_loss: 2.6745 - val_accuracy: 0.1359\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 2.6115 - accuracy: 0.1522 - val_loss: 2.5130 - val_accuracy: 0.1810\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 2.4423 - accuracy: 0.2045 - val_loss: 2.3649 - val_accuracy: 0.2418\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 2.3073 - accuracy: 0.2474 - val_loss: 2.2363 - val_accuracy: 0.2733\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 2.1938 - accuracy: 0.2771 - val_loss: 2.1436 - val_accuracy: 0.2904\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 2.0946 - accuracy: 0.2946 - val_loss: 2.0564 - val_accuracy: 0.3097\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 2.0182 - accuracy: 0.3110 - val_loss: 1.9996 - val_accuracy: 0.3124\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.9633 - accuracy: 0.3234 - val_loss: 1.9469 - val_accuracy: 0.3259\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 1.9166 - accuracy: 0.3368 - val_loss: 1.8985 - val_accuracy: 0.3564\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.8701 - accuracy: 0.3571 - val_loss: 1.9217 - val_accuracy: 0.3566\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.8356 - accuracy: 0.3693 - val_loss: 1.8289 - val_accuracy: 0.3754\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.8028 - accuracy: 0.3802 - val_loss: 1.8037 - val_accuracy: 0.3896\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.7741 - accuracy: 0.3902 - val_loss: 1.7688 - val_accuracy: 0.3945\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.7442 - accuracy: 0.3992 - val_loss: 1.7577 - val_accuracy: 0.4013\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.7239 - accuracy: 0.4052 - val_loss: 1.7238 - val_accuracy: 0.4148\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.6801 - accuracy: 0.4173 - val_loss: 1.6871 - val_accuracy: 0.4225\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.6496 - accuracy: 0.4277 - val_loss: 1.6844 - val_accuracy: 0.4127\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.6238 - accuracy: 0.4326 - val_loss: 1.6480 - val_accuracy: 0.4333\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.6009 - accuracy: 0.4386 - val_loss: 1.6113 - val_accuracy: 0.4383\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.5807 - accuracy: 0.4469 - val_loss: 1.6244 - val_accuracy: 0.4263\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.5610 - accuracy: 0.4508 - val_loss: 1.5692 - val_accuracy: 0.4517\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.5422 - accuracy: 0.4556 - val_loss: 1.5660 - val_accuracy: 0.4441\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.5206 - accuracy: 0.4611 - val_loss: 1.5504 - val_accuracy: 0.4527\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.5025 - accuracy: 0.4674 - val_loss: 1.5444 - val_accuracy: 0.4491\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.4902 - accuracy: 0.4662 - val_loss: 1.5057 - val_accuracy: 0.4669\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.4656 - accuracy: 0.4759 - val_loss: 1.5217 - val_accuracy: 0.4619\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.4531 - accuracy: 0.4822 - val_loss: 1.4965 - val_accuracy: 0.4712\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.4343 - accuracy: 0.4874 - val_loss: 1.4980 - val_accuracy: 0.4710\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.4252 - accuracy: 0.4906 - val_loss: 1.4653 - val_accuracy: 0.4875\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.4141 - accuracy: 0.4960 - val_loss: 1.4540 - val_accuracy: 0.4891\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3971 - accuracy: 0.5010 - val_loss: 1.4563 - val_accuracy: 0.4839\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3875 - accuracy: 0.5048 - val_loss: 1.4397 - val_accuracy: 0.4877\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3708 - accuracy: 0.5108 - val_loss: 1.4253 - val_accuracy: 0.5072\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3638 - accuracy: 0.5112 - val_loss: 1.4301 - val_accuracy: 0.4953\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3505 - accuracy: 0.5168 - val_loss: 1.4244 - val_accuracy: 0.4853\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3397 - accuracy: 0.5185 - val_loss: 1.4230 - val_accuracy: 0.4940\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3291 - accuracy: 0.5229 - val_loss: 1.3786 - val_accuracy: 0.5095\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3185 - accuracy: 0.5235 - val_loss: 1.3913 - val_accuracy: 0.5147\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3126 - accuracy: 0.5274 - val_loss: 1.3718 - val_accuracy: 0.5198\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.3013 - accuracy: 0.5301 - val_loss: 1.3743 - val_accuracy: 0.5107\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.2907 - accuracy: 0.5341 - val_loss: 1.3516 - val_accuracy: 0.5191\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 1.2814 - accuracy: 0.5358 - val_loss: 1.3422 - val_accuracy: 0.5301\n",
      "Model: \"basic_conv_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling2d_20 (MaxPoolin  multiple                 0 (unused)\n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          multiple                  160       \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          multiple                  2320      \n",
      "                                                                 \n",
      " time_distributed_32 (TimeDi  multiple                 0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          multiple                  4640      \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          multiple                  9248      \n",
      "                                                                 \n",
      " time_distributed_33 (TimeDi  multiple                 0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              multiple                  1720      \n",
      "                                                                 \n",
      " time_distributed_34 (TimeDi  multiple                 407       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,495\n",
      "Trainable params: 18,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Test compile\n",
    "#print(train_dataset)\n",
    "#for imgs, targets in train_dataset.take(1):\n",
    "#  print(targets)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              #loss=\"mean_squared_error\",\n",
    "              metrics=[\n",
    "                      tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "                      #tf.keras.metrics.Accuracy(name=\"accuracy\"),\n",
    "                      #tf.keras.metrics.Mean(name=\"frob_norm\")\n",
    "                      ]\n",
    "              )\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=50)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "Yd8MuzB_-7mb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "outputId": "692d2ac0-1eb4-47a4-a8d8-e93cc38c51dc"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\ntfds.benchmark(train_dataset, batch_size=batch_size)\\n\\nprint(\"\\n************ Training UNTOUCHED ************\\n\")\\n\\nmemory = {\"test_accuracy\" : [],\\n          \"test_loss\" : [],\\n          \"test_frob_norm\" : [],\\n          \"train_accuracy\" : [],\\n          \"train_loss\" : [],\\n          \"train_frob_norm\" : []\\n          }\\n\\nmemory = training_loop(model,\\n                       train_ds=train_dataset,\\n                       test_ds=val_dataset,\\n                       epochs=tf.constant(epochs),\\n                       train_summary_writer=train_summary_writer,\\n                       memory=memory)\\n\\nvisualization(memory[\"train_accuracy\"], memory[\"train_loss\"], memory[\"train_frob_norm\"], \"aug_train\")\\n'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "\"\"\"\n",
    "tfds.benchmark(train_dataset, batch_size=batch_size)\n",
    "\n",
    "print(\"\\n************ Training UNTOUCHED ************\\n\")\n",
    "\n",
    "memory = {\"test_accuracy\" : [],\n",
    "          \"test_loss\" : [],\n",
    "          \"test_frob_norm\" : [],\n",
    "          \"train_accuracy\" : [],\n",
    "          \"train_loss\" : [],\n",
    "          \"train_frob_norm\" : []\n",
    "          }\n",
    "\n",
    "memory = training_loop(model,\n",
    "                       train_ds=train_dataset,\n",
    "                       test_ds=val_dataset,\n",
    "                       epochs=tf.constant(epochs),\n",
    "                       train_summary_writer=train_summary_writer,\n",
    "                       memory=memory)\n",
    "\n",
    "visualization(memory[\"train_accuracy\"], memory[\"train_loss\"], memory[\"train_frob_norm\"], \"aug_train\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "ki_uebungen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f29be5cdbd889ccae82f59fdf4d8dd89ee7979a66140a153cd0c4d342f0eb10a"
   }
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
